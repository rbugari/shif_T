# COMMAND ----------
# Title: Filter_Data_With_Parameter
# Auto-Generated by Shift-T Developer Agent
# --------------------------------------------------

# 1. Setup & Config
from delta.tables import *
from pyspark.sql.functions import *
from pyspark.sql.types import *

# 2. Reading Bronze / Source
# NOTE: Replace 'source_db.source_product' with the actual source table/view name
# For demonstration, we assume the source table is 'bronze.Product_raw'
df_source = spark.read.table('bronze.Product_raw')

# 3. Transformations (Apply Logic)
# Explicitly cast all columns to match the target schema
# Target Schema:
# ProductID: INTEGER
# Name: INTEGER
# ProductNumber: STRING
# Color: STRING
# SafetyStockLevel: STRING
# ListPrice: DECIMAL(19,4)
# Size: STRING

df_transformed = df_source.select(
    col('ProductID').cast('integer').alias('ProductID'),
    col('Name').cast('integer').alias('Name'),
    col('ProductNumber').cast('string').alias('ProductNumber'),
    col('Color').cast('string').alias('Color'),
    col('SafetyStockLevel').cast('string').alias('SafetyStockLevel'),
    col('ListPrice').cast('decimal(19,4)').alias('ListPrice'),
    col('Size').cast('string').alias('Size')
)

# 4. Lookup Logic (if any)
# No lookups defined in this task.

# 5. Writing to Silver/Gold (Apply Platform Pattern)
# Idempotent write: OVERWRITE the Product table (no SCD, no PK, standard table)
# Target table: gold.Product

df_transformed.write.format('delta').mode('overwrite').option('overwriteSchema', 'true').saveAsTable('gold.Product')

# Optional: Z-ORDER optimization on ProductNumber (high-cardinality business key)
spark.sql('OPTIMIZE gold.Product ZORDER BY (ProductNumber)')
