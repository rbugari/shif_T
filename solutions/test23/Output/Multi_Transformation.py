# COMMAND ----------
# Title: Multi_Transformation.dtsx
# Auto-Generated by Shift-T Developer Agent
# --------------------------------------------------

# 1. Setup & Config
from delta.tables import *
from pyspark.sql.functions import *
from pyspark.sql.types import *

# 2. Reading Bronze / Source
# NOTE: Replace 'bronze.product_source' with the actual source table name
# Schema enforced as per Target Schema
product_schema = StructType([
    StructField("ProductID", IntegerType(), False),
    StructField("Name", IntegerType(), False),
    StructField("ProductNumber", StringType(), False),
    StructField("Color", StringType(), False),
    StructField("SafetyStockLevel", StringType(), False),
    StructField("ListPrice", DecimalType(19, 4), False),
    StructField("Size", StringType(), False)
])
df_source = spark.read.table("bronze.product_source")
df_source = df_source.select(
    col("ProductID").cast(IntegerType()),
    col("Name").cast(IntegerType()),
    col("ProductNumber").cast(StringType()),
    col("Color").cast(StringType()),
    col("SafetyStockLevel").cast(StringType()),
    col("ListPrice").cast(DecimalType(19, 4)),
    col("Size").cast(StringType())
)

# 3. Transformations (Apply Logic)
# No additional transformations specified in SSIS logic.
df_transformed = df_source

# 4. Lookup Logic (if any)
# No lookups specified.

# 5. Writing to Silver/Gold (Apply Platform Pattern)
# Idempotent overwrite (no SCD, no identity, standard table)
# Replace 'silver.Product' with your actual target table location
(
    df_transformed
    .write
    .format("delta")
    .mode("overwrite")
    .option("overwriteSchema", "true")
    .saveAsTable("silver.Product")
)

# Optional: Z-ORDER optimization on high-cardinality columns (e.g., ProductID, ProductNumber)
spark.sql("OPTIMIZE silver.Product ZORDER BY (ProductID, ProductNumber)")
